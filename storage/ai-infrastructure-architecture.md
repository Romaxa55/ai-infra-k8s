# ğŸš€ AI Infrastructure Architecture - ĞœĞĞšĞ¡Ğ˜ĞœĞĞ›Ğ¬ĞĞĞ¯ ĞœĞĞ©ĞĞĞ¡Ğ¢Ğ¬

## ğŸ’ª Ğ–ĞµĞ»ĞµĞ·Ğ¾ ÑĞµÑ€Ğ²ĞµÑ€Ğ°

- **CPU**: 40 cores (Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ 35 Ğ´Ğ»Ñ Ollama + 8 Ğ´Ğ»Ñ Open WebUI)
- **RAM**: 96GB (80GB Ğ´Ğ»Ñ Ollama + 16GB Ğ´Ğ»Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ¸ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²)
- **GPU**: NVIDIA RTX 3050 Ñ CUDA
- **Storage**: 1TB NVMe SSD + longhorn distributed storage
- **Network**: Kubernetes cluster Ğ½Ğ° k3s

## ğŸ—ï¸ ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI INFRASTRUCTURE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸŒ Open WebUI (v0.6.12)           â”‚  ğŸ’¾ Storage Layer     â”‚
â”‚  â”œâ”€ 16GB RAM, 8 CPU cores          â”‚  â”œâ”€ Open WebUI: 100GB â”‚
â”‚  â”œâ”€ WebSocket + Redis cache        â”‚  â”œâ”€ Ollama: 500GB     â”‚
â”‚  â”œâ”€ RAG + File processing          â”‚  â”œâ”€ MinIO: 200GB      â”‚
â”‚  â””â”€ Multi-model interface          â”‚  â””â”€ JupyterHub: 50GB  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¤– Embedded Ollama Engine          â”‚  ğŸ”„ Backup Services    â”‚
â”‚  â”œâ”€ 80GB RAM, 35 CPU cores         â”‚  â”œâ”€ Standalone Ollama  â”‚
â”‚  â”œâ”€ 8 models loaded simultaneously â”‚  â”‚  â””â”€ 64GB, 20 cores  â”‚
â”‚  â”œâ”€ 16 parallel requests           â”‚  â”œâ”€ Model backups      â”‚
â”‚  â”œâ”€ GPU acceleration (RTX 3050)    â”‚  â””â”€ MinIO storage      â”‚
â”‚  â””â”€ 500GB SSD storage              â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âš¡ Performance Layer               â”‚  ğŸ” Security & Network â”‚
â”‚  â”œâ”€ Redis: 8GB cache               â”‚  â”œâ”€ Load Balancer      â”‚
â”‚  â”œâ”€ Pipelines: 8GB, 4 cores        â”‚  â”œâ”€ SSL termination    â”‚
â”‚  â”œâ”€ WebSocket manager              â”‚  â”œâ”€ ingress-nginx      â”‚
â”‚  â””â”€ Real-time communication        â”‚  â””â”€ ai.local domain    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¤– AI Models Strategy

### Primary Models (Embedded Ollama - 80GB RAM)
```yaml
Fast Models (GPU Optimized):
  - llama3.1:8b          # 5GB   - Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ chat
  - qwen2.5-coder:14b     # 8GB   - ĞšĞ¾Ğ´ Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
  - mistral:7b            # 4GB   - ĞĞ±Ñ‰Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸

Power Models (CPU+GPU):
  - devstral:24b          # 14GB  - ĞŸÑ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ğ¾Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
  - qwen2.5-coder:32b     # 19GB  - ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ´
  - deepseek-r1:14b       # 9GB   - Reasoning Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
  - deepseek-r1:32b       # 19GB  - Ğ“Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·

Super Models (Ñ Ñ‚Ğ°ĞºĞ¸Ğ¼ Ğ¶ĞµĞ»ĞµĞ·Ğ¾Ğ¼ Ğ¼Ğ¾Ğ¶ĞµĞ¼!):
  - llama3.3:70b          # 40GB  - Ğ¢Ğ¾Ğ¿ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ñ‚ Meta
  - qwen2.5:72b           # 41GB  - ĞšĞ¸Ñ‚Ğ°Ğ¹ÑĞºĞ¸Ğ¹ Ğ³Ğ¸Ğ³Ğ°Ğ½Ñ‚
  - codellama:70b         # 40GB  - ĞšĞ¾Ğ´ Ğ²Ñ‹ÑÑˆĞµĞ³Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ

Utility Models:
  - llama3.2:3b           # 2GB   - Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
  - llama3.2:1b           # 1GB   - ĞœĞ¸ĞºÑ€Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
```

### Backup Models (Standalone Ollama - 64GB RAM)
- Ğ”ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
- Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
- ĞÑ€Ñ…Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ

## ğŸ“Š Resource Allocation

### Memory Distribution (96GB Total)
```
Ollama Engine:        80GB (83%)
â”œâ”€ Model Loading:     ~70GB
â”œâ”€ KV Cache:          ~8GB
â””â”€ Processing:        ~2GB

Open WebUI:           16GB (17%)
â”œâ”€ Application:       ~4GB
â”œâ”€ File Processing:   ~8GB
â”œâ”€ Chat History:      ~2GB
â””â”€ Buffer:            ~2GB

System & Services:    16GB (Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ)
â”œâ”€ Kubernetes:        ~4GB
â”œâ”€ Redis Cache:       ~8GB
â”œâ”€ Pipelines:         ~2GB
â””â”€ OS:                ~2GB
```

### CPU Distribution (40 cores)
```
Ollama Engine:        35 cores (87.5%)
â”œâ”€ Model Inference:   ~25 cores
â”œâ”€ Parallel Requests: ~8 cores
â””â”€ GPU Communication: ~2 cores

Open WebUI:           8 cores (20%)
â”œâ”€ Web Interface:     ~4 cores
â”œâ”€ File Processing:   ~3 cores
â””â”€ Background Tasks:  ~1 core

Services:             5 cores (Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ)
â”œâ”€ Redis:             ~2 cores
â”œâ”€ Pipelines:         ~2 cores
â””â”€ System:            ~1 core
```

## ğŸš€ Performance Optimizations

### Ollama Engine
```yaml
Environment Variables:
  OLLAMA_MAX_LOADED_MODELS: 8     # 8 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
  OLLAMA_NUM_PARALLEL: 16        # 16 Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
  OLLAMA_MAX_QUEUE: 1024         # Ğ‘Ğ¾Ğ»ÑŒÑˆĞ°Ñ Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ
  OLLAMA_FLASH_ATTENTION: 1      # Ğ‘Ñ‹ÑÑ‚Ñ€Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ
  OLLAMA_KV_CACHE_TYPE: f16      # ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºÑÑˆĞ°
  OLLAMA_KEEP_ALIVE: 24h         # ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ 24 Ñ‡Ğ°ÑĞ°
```

### Open WebUI
```yaml
Features:
  - FILE_SIZE_LIMIT: 5GB         # Ğ‘Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
  - WEBSOCKET_SUPPORT: enabled   # Real-time
  - RAG_WEB_SEARCH: enabled      # ĞŸĞ¾Ğ¸ÑĞº Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ
  - REDIS_CACHE: 8GB             # ĞœĞ¾Ñ‰Ğ½Ğ¾Ğµ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
```

### Redis Cache
```yaml
Configuration:
  - Memory: 8GB                   # Ğ‘Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ ĞºÑÑˆ
  - Persistence: enabled          # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ĞºÑÑˆĞ°
  - WebSocket Manager: enabled    # Real-time ĞºĞ¾Ğ¼Ğ¼ÑƒĞ½Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
```

## ğŸ”„ Model Loading Strategy

### Hot Models (Ğ²ÑĞµĞ³Ğ´Ğ° Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸)
1. **qwen2.5-coder:14b** - Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
2. **llama3.1:8b** - Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹
3. **mistral:7b** - Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸

### Warm Models (Ğ±Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ°)
4. **devstral:24b** - ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
5. **deepseek-r1:14b** - Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¸ reasoning
6. **llama3.2:3b** - Ğ»ĞµĞ³ĞºĞ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸

### Cold Models (Ğ¿Ğ¾ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ)
7. **llama3.3:70b** - Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾
8. **qwen2.5:72b** - ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
9. **codellama:70b** - Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ´

## ğŸ“ Storage Architecture

### SSD Storage (longhorn-ssd)
```
Total Allocation: ~1TB
â”œâ”€ Ollama Models:     500GB
â”œâ”€ Open WebUI Data:   100GB
â”œâ”€ MinIO Objects:     200GB
â”œâ”€ JupyterHub:        50GB
â”œâ”€ Redis Persistence: 10GB
â”œâ”€ System:            50GB
â””â”€ Reserve:           90GB
```

### Storage Strategy
- **Hot storage**: ĞĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° SSD
- **Warm storage**: Backup Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° HDD
- **Cold storage**: ĞÑ€Ñ…Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² MinIO

## ğŸŒ Network Architecture

### Services Mesh
```
External Access:
â”œâ”€ ai.local:80 â†’ Open WebUI
â”œâ”€ minio.local:9001 â†’ MinIO Console
â””â”€ jupyter.local:8000 â†’ JupyterHub

Internal Services:
â”œâ”€ open-webui-ollama:11434 â†’ Primary Ollama
â”œâ”€ ollama-standalone:11435 â†’ Backup Ollama
â”œâ”€ open-webui-redis:6379 â†’ Redis Cache
â”œâ”€ open-webui-pipelines:9099 â†’ AI Pipelines
â””â”€ minio:9000 â†’ Object Storage
```

## ğŸ¯ Performance Expectations

### Model Performance
```
Small Models (1-8B):
â”œâ”€ Response Time: 100-500ms
â”œâ”€ Throughput: 20-50 tokens/sec
â””â”€ Concurrent Users: 10-20

Medium Models (14-32B):
â”œâ”€ Response Time: 500ms-2s
â”œâ”€ Throughput: 10-30 tokens/sec
â””â”€ Concurrent Users: 5-10

Large Models (70B+):
â”œâ”€ Response Time: 1-5s
â”œâ”€ Throughput: 5-15 tokens/sec
â””â”€ Concurrent Users: 2-5
```

### System Performance
- **Memory Utilization**: 85-90%
- **CPU Utilization**: 70-85%
- **GPU Utilization**: 80-95%
- **Storage IOPS**: 10,000+

## ğŸ”§ Monitoring & Scaling

### Key Metrics
- Model load times
- Request queue length
- Memory utilization per model
- GPU utilization
- Cache hit rates
- Response latencies

### Scaling Strategy
1. **Vertical**: Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²
2. **Horizontal**: Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑƒĞ·Ğ»Ğ¾Ğ²
3. **Model**: Ğ‘Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
4. **Cache**: ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºÑÑˆĞ°

## ğŸ‰ Ğ˜Ñ‚Ğ¾Ğ³Ğ¸

Ğ­Ñ‚Ğ° AI Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ **ĞœĞĞĞ¡Ğ¢Ğ  ĞœĞĞ¨Ğ˜ĞĞ£** Ğ´Ğ»Ñ AI Ğ·Ğ°Ğ´Ğ°Ñ‡:

âœ… **8 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸**
âœ… **16 Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²**
âœ… **5GB Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸**
âœ… **Real-time WebSocket ĞºĞ¾Ğ¼Ğ¼ÑƒĞ½Ğ¸ĞºĞ°Ñ†Ğ¸Ñ**
âœ… **ĞœĞ¾Ñ‰Ğ½Ğ¾Ğµ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Redis**
âœ… **Backup Ğ¸ failover ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹**
âœ… **GPU ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ**
âœ… **ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹**

**Ğ­Ñ‚Ğ¾ AI infrastructure Ğ¼ĞµÑ‡Ñ‚Ñ‹!** ğŸš€ğŸ¤–ğŸ’ª 