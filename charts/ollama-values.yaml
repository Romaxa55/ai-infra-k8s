# Ollama Helm Chart Values
nameOverride: "ollama"
fullnameOverride: "ollama"

# Namespace
namespace: ai-infra

# Node selection (как у Frigate)
nodeSelector:
  node: pve

# Runtime class для GPU
runtimeClassName: nvidia

# Tolerations for master node
tolerations:
  - key: node-role
    operator: Equal
    value: backup
    effect: NoSchedule

# Resources без GPU (GPU доступен через runtimeClassName)
resources:
  requests:
    memory: "2Gi"
    cpu: "1000m"
  limits:
    memory: "8Gi"
    cpu: "4000m"

# Persistence
persistence:
  enabled: true
  storageClass: "longhorn-ssd"
  size: 200Gi
  accessModes:
    - ReadWriteOnce

# Service configuration
service:
  type: ClusterIP
  port: 11434

# Environment variables
env:
  OLLAMA_HOST: "0.0.0.0"
  OLLAMA_ORIGINS: "*"

# Probes
livenessProbe:
  enabled: true
  httpGet:
    path: /
    port: 11434
  initialDelaySeconds: 60
  periodSeconds: 30

readinessProbe:
  enabled: true
  httpGet:
    path: /
    port: 11434
  initialDelaySeconds: 30
  periodSeconds: 10 